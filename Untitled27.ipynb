{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1.1\n",
        "Transponowana konwolucja to transpozycja mapy liniowej zdefiniowanej przez standardową konwolucję. Czyli jeśli mamy jądro K:\n",
        "$$\\mathbf{y}=W \\mathbf{x}$$\n",
        "dla pewnej macierzy W=W(K), to transponowana konwolucja:\n",
        "$$\\hat{\\mathbf{y}}=W^{T} \\mathbf{x}$$\n",
        "gdzie $\\hat{\\mathbf{y}}$ to wyjściowy wektor, czyli upsamplowana\\odtworzona mapa cech.\n",
        "\n",
        "$W^{T}$ \"rozkłada\" każdy piksel wyjściowy z $\\mathbf{x}$  na blok $k\\times k$ pikseli wyjściowych (gdzie $\\mathbf{y}$ jest $k\\times k$). W ten sposób zwiększa się rozdzielczość przestrzenna.\n",
        "\n",
        "1.2\n",
        "\n",
        "W przypadku standardowej konwolucji rozdzielczość przestrzenna zmniejsza się (np przy użyciu Conv2d), czyli kilka wejściowych pikseli jest łączonych w pojedynczy wyjściowy piksel, czyli zmniejsza się mapa cech.\n",
        "\n",
        "Gdyż przy ConvTranspose2d jeden piksel przechodzi na wiele, jak już zostało opisane, to zwiększa wymiary przestrzenne.\n",
        "\n",
        "przy Conv2d mamy równanie $\\mathbf{y}=W \\mathbf{x}$, przy ConvTranspose2d transponujemy wagi: $\\hat{\\mathbf{y}}=W^{T} \\mathbf{x}$.\n",
        "\n",
        "W przypadku ConvTranspose2d mamy operację\\działanie \"stride\" (gdy s>1), czyli wstawianie zer, co jest potrzebne do rozszerzania siatki.\n",
        "Przy Conv2d dla stride: s > 1, jądro przesuwa się po wejściu o $s$ pikseli za każdym krokiem, czyli \"pomija\" po $s-1$ pikseli za każdym razem.\n",
        "czyli mapa wyjściowa zostaje pomniejszona (downsampling) o około $s$ w każdym wymiarze.\n",
        "\n",
        "W ConvTranspose2d przy $s>1$ wstawiamy między wiersze i kolumny wejścia po $s-1$ zer, dalej wykonujemy standardową konwolucję ze stride $=1$.\n",
        "Czyli mapa wyjściowa zostaje powiększona (upsampling) o około $s$ w każdym wymiarze.\n",
        "Pomiędzy każdy oryginalny wiersz macierzy wejściowej wstawiamy dokładnie $s-1$ wierszy z zerami.\n",
        "początkowy wymiar:  $H\\times W$ = liczba wierszy w macierzy wejściowej $\\times $ liczba kolumn w macierzy wejściowej, to po wstawieniu zer liczba wierszy wyniesie\n",
        "\n",
        "$$\n",
        "\\tilde{H}=\\left(H-1\\right) s+1\n",
        "$$\n",
        "\n",
        "Pomiędzy każdą parą sąsiednich kolumn wstawiamy $s-1$ zerowych kolumn. Po wstawieniu zer liczba kolumn wynosi\n",
        "\n",
        "$$\n",
        "\\tilde{W}=\\left(W-1\\right) s+1\n",
        "$$\n",
        "\n",
        "\n",
        "W Conv2d padding dodaje\\\"przykleja\" do wejściowej macierzy zerowe wiersze na górze i na dole oraz zerowe kolumny z lewej i z prawej strony (czyli zwiększa wymiar).\n",
        "W ConvTranspose2d padding też \"przykleja\" do wejściowej macierzy zerowe wiersze na górze i na dole oraz zerowe kolumny z lewej i z prawej strony.\n",
        "output_padding (którego nie ma w Conv2d) w ConvTranspose2d usuwa górne wiersze oraz lewe kolumny, aby rozmiar\\wymiar był odpowiedni początkowemy wejściu (macierzy wejściowej). albo dodaje\\\"przykleja\" w prawym-dolnym rogu, aby wymiary się zgadzały.\n",
        "\n",
        "Czyli za pomocą ConvTranspose2d, dobierając hiperparametry (padding, output_padding, stride, kernel), można odwrócić działanie konwolucji i przywróć oryginalny rozmiar wejścia.\n",
        "\n",
        "Rozmiar jądra ($k\\times k$) — większe k \"rozciąga\" każdy piksel wejściowy na szerszą siatkę, zwiększając rozmiar wyjścia (w przypadku Conv2d działa odwrotnie).\n",
        "\n",
        "Pozostałe parametry (są jak w Conv2d, tak i w ConvTranspose2d):\n",
        "\n",
        "bias - współczynnik przesunięcia (bias). Oznacza to, że oprócz operacji splotu, dla każdej wartości macierzy wyjściowej dodajemy wartość $b$, która aktualizowana podczas treningu.\n",
        "\n",
        "dilation - odstęp pomiędzy kolejnymi elementami jądra konwolucji.\n",
        "\n",
        "\n",
        "1.3\n",
        "\n",
        "Niech hiperparametry mają następujące wartości:\n",
        "stride $s = 2$,\n",
        "padding $p = 1$,\n",
        "output_padding $op = 1$,\n",
        "kernel $k = 3$,\n",
        "bias $b = 1$,\n",
        "dilation $d = 1$,\n",
        "groups $g = 1$.\n",
        "\n",
        "\n",
        "Dodawanie zer zostało opisane powyżej.\n",
        "Dopełniamy rozszerzoną siatkę \"warstwą\" zer o grubości\n",
        "$$\n",
        "p_{\\text {full }}=d(k-1)-p\n",
        "$$\n",
        "z każdej strony. Dzięki temu jądro konwolucji może się przesuwać również po brzegach.\n",
        "Następnie wykonujemy zwykłą konwolucję ze stride $=1$ :\n",
        "- Dla każdego elementu macierzy wejciowej $x_{ij}$ (jeśli jest różny od zera) mnożymy całe jądro $W$ przez tę wartość.\n",
        "- Powstaje w ten sposób blok (odcisk) o wymiarach $k\\times k$.\n",
        "- Przesuwamy odcisk na wynikową siatkę tak, aby jego lewy górny róg pokrywał się z pozycją $(i,j)$, i sumujemy wartości element po elemencie.\n",
        "Alternatywnie dla każdej pozycji nakładamy odcisk na macierz zerową w tej samej lokalizacji, a następnie sumujemy wszystkie odciski (tam, gdzie się nakładają, dodajemy wartości).\n",
        "\n",
        "\n",
        "\n",
        "Dalsze kroki: usuń z góry dokładnie $p$ wierszy oraz z lewej $p$ kolumn (parametr padding).  \n",
        "Na dole i po prawej stronie zachowaj $op$ wierszy i kolumn (parametr output_padding).  \n",
        "Do każdego kanału wyjściowego dodaj skalar $b$ (bias).\n",
        "\n",
        "\n",
        "\n",
        "Czyli mamy:\n",
        "\n",
        "\n",
        "\\begin{aligned}\n",
        "H_\\text{out} &= (H_\\text{in}-1)\\,s_h + K_h - 2p_h + op_h,\\\\\n",
        "W_\\text{out} &= (W_\\text{in}-1)\\,s_w + K_w - 2p_w + op_w.\n",
        "\\end{aligned}\n",
        "\n",
        "\n",
        "Gdzie w naszym przypadku:  $(H_\\text{in}=W_\\text{in}=2;k=3;s=2;p=1;op=1)$. Otrzymujemy\n",
        "$(H_\\text{out}=W_\\text{out}=4)$.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "1. parametry\n",
        "   - b=1, s=2, p=1 – bias, stride i padding  \n",
        "   - X i W – oryginalna macierz wejściowa 2×2 oraz jądro 3×3.\n",
        "\n",
        "2. Zero-insertion\n",
        "   - Wstawiamy $s-1=1$ zerowy wiersz i kolumnę pomiędzy elementy oryginału.  \n",
        "   - Powstaje $\\tilde X$ o wymiarach 3×3, z żółtym zaznaczeniem oryginalnych wartości.\n",
        "\n",
        "3. padding (p=1) i podział na M₀₀, M₁₁, M₁₀, M₀₁  \n",
        "   - Dopełniamy siatkę zerami, aby uzyskać 5×5 (ramka wokół żółtego pola).  \n",
        "   - Tworzymy odciski jądra z dwóch niezerowych pikseli: fioletowy (M₀₀) i czerwony (M₁₁).  \n",
        "   - Zielone i pomarańczowe to odciski z miejsc, gdzie wejście było zero (nie wpływają na sumę).\n",
        "\n",
        "4. Suma odcisków  \n",
        "   - Nakładamy odciski element-po-elemencie i sumujemy, co daje macierz 5×5.\n",
        "\n",
        "5. Dodawanie biasu ($b=1$)  \n",
        "   - Do każdej wartości powstałej macierzy dodajemy 1.  \n",
        "   - Mamy wstępny wynik 5×5 po biasie.\n",
        "\n",
        "6. output_padding = 1  \n",
        "   - Obcinamy pierwszy wiersz i kolumnę z lewej, uzyskujemy podmacierz 4×4 (różowe pole).  \n",
        "   - Wynik końcowy - macierz 4×4  \n",
        "  \n",
        "\n",
        "\n",
        "Bibliografia:\n",
        "https://www.geeksforgeeks.org/apply-a-2d-transposed-convolution-operation-in-pytorch/\n",
        "https://d2l.ai/chapter_computer-vision/transposed-conv.html\n",
        "https://docs.pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html\n"
      ],
      "metadata": {
        "id": "yDcF_SO6C9I9"
      }
    }
  ]
}